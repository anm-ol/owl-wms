#for no-pose training : torchrun --nproc_per_node=8 -m train --config_path configs/t3/simple.yml
model:
  model_id: dcae
  sample_size: [448, 736]
  channels: 3
  latent_size: 8
  latent_channels: 128
  ch_0: 128
  ch_max: 1024
  encoder_blocks_per_stage: [4, 4, 4, 4, 4]
  decoder_blocks_per_stage: [4, 4, 4, 4, 4]
  use_middle_block: false

train:
  trainer_id: rec
  data_id: t3
  data_kwargs: {}
  
  # --- ADD THIS KEY BACK IF IT IS MISSING ---
  target_batch_size: 128
  
  batch_size: 16

  epochs: 200

  opt: AdamW
  opt_kwargs:
    lr: 3.0e-5
    weight_decay: 1.0e-4
    betas: [0.9, 0.95]
    eps: 1.0e-15

  lpips_type: convnext
  loss_weights:
    kl: 1.0e-6
    lpips: 12.0
    l2: 1.0

  scheduler: LinearWarmup
  scheduler_kwargs:
    warmup_steps: 500
    min_lr: 3.0e-6


  checkpoint_dir: checkpoints/t3_VAE_nopose_v1
  resume_ckpt: checkpoints/t3_VAE_nopose_v1/step_11000.pt

  sample_interval: 200
  save_interval: 1000

wandb:
  name: ${env:praymesh}
  project: t3VAE
  run_name: tekken_vae_H200_v7