# configs/tekken_rft_train.yml
model:
  model_id: tekken_rft
  sample_size: [14, 23]     # Latent H, W from your VAE
  channels: 128             # Latent channels from your VAE
  n_actions: 256            # For the action embedding layer
  n_layers: 12
  n_heads: 8
  d_model: 768
  # tokens_per_frame will be calculated inside the model as 14*23=322
  n_frames: 16              # This is the window length
  cfg_prob: 0.1
  causal: true
  uncond: false
  backbone: dit
  has_audio: false

  local_window: 16
  global_window: 16

train:
  trainer_id: tekken_rft
  data_id: t3
  data_kwargs:
    window_length: 16
    root_dir: "preproccessing/cached_data_ltx"

  target_batch_size: 8
  batch_size: 4 # Adjust based on your GPU memory

  epochs: 100
  opt: AdamW
  opt_kwargs:
    lr: 1.0e-4
    weight_decay: 0.01

  sample_interval: 1000
  save_interval: 5000
  n_samples: 4

  # VAE settings for decoding samples
  vae_id: ltx # Not a built-in HF VAE
  vae_cfg_path: null # Path to your VAE config
  vae_ckpt_path: "/home/venky/ankitd/anmol/WM/owl-wms/preproccessing/checkpoints/LTXV/vae" # Path to your VAE checkpoint
  vae_scale: 1.0 # Adjust if your VAE has a scaling factor
  vae_batch_size: 4

wandb:
  name: d-fusion
  project: OWL
  run_name: tekken-rft-v0.1