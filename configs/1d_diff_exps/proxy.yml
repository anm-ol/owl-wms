# Config for a simple 256 -> 16 autoencoder
model:
  model_id: proxy_titok
  sample_size: 256
  channels: 3
  latent_size: 16
  latent_channels: 128

  proxy_size: 16
  proxy_channels: 16
  
  noise_decoder_inputs: 0.0
  
  n_layers: 28
  n_heads: 24
  d_model: 1536

  patch_size: 16
  proxy_patch_size: 1

train:
  trainer_id: proxy
  data_id: s3_imagenet

  target_batch_size: 256
  batch_size: 32

  epochs: 200

  opt: Muon
  opt_kwargs:
    lr: 1.0e-3
    momentum: 0.95
    adamw_lr: 1.0e-4
    adamw_wd: 1.0e-4
    adamw_eps: 1.0e-15
    adamw_betas: [0.9, 0.95]
    adamw_keys: [encoder.proj_in, encoder.proj_out, decoder.proj_in, decoder.proj_out, encoder.latent_tokens, decoder.image_tokens]

  loss_weights:
    lpips: 0.0
    latent_reg: 1.0e-6

  scheduler: LinearWarmup
  scheduler_kwargs:
    warmup_steps: 3000
    min_lr: 1.0e-5

  checkpoint_dir: checkpoints/2d_128x_proxy

  sample_interval: 1000
  save_interval: 10000

  teacher_ckpt: checkpoints/vae_16x_c16_100k_ckpt.pt
  teacher_cfg: configs/1d_diff_exps/teacher_1.yml

wandb:
  name: shahbuland
  project: new_vaes
  run_name: 128x_proxy